{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c410a518",
   "metadata": {},
   "source": [
    "\n",
    "# Wine in a Million\n",
    "\n",
    "### Authors: __[Zephyr Headley](https://github.com/jzheadley)__ and __[John Naylor](https://jonaylor.xyz)__\n",
    "\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/jonaylor89/WineInAMillion/blob/main/notebooks/Wine%20In%20A%20Million.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "81e12a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.1.0)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (3.6.2)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (0.24.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (4.13.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (4.61.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (1.5.3)\n",
      "Requirement already satisfied: tokenizers>=0.10.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (0.2.1)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (0.1.96)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (1.10.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence_transformers) (0.5.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch>=1.6.0->sentence_transformers) (3.10.0.2)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch>=1.6.0->sentence_transformers) (0.8)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (4.8.2)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.46)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (5.4.1)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nltk->sentence_transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nltk->sentence_transformers) (8.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.26.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->sentence_transformers) (8.3.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (7.352.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker SDK Version: 2.68.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 146;\n",
       "                var nbb_unformatted_code = \"!pip install sentence_transformers\\n!pip install nvidia-ml-py3\\n\\nimport os\\nimport tarfile\\nimport json\\nimport time\\nimport pandas as pd\\nimport boto3\\nimport joblib\\nimport sagemaker\\nfrom time import gmtime, strftime\\nfrom sagemaker import get_execution_role\\nfrom sagemaker.amazon.amazon_estimator import image_uris\\nfrom sagemaker.serializers import JSONSerializer\\nfrom sagemaker.deserializers import JSONDeserializer\\nfrom sentence_transformers import SentenceTransformer\\nfrom sagemaker.sklearn import SKLearnModel\\nfrom sagemaker.pytorch import PyTorch, PyTorchModel\\nfrom sagemaker.predictor import Predictor\\nfrom sagemaker.inputs import TrainingInput\\nfrom sklearn.neighbors import NearestNeighbors\\nfrom sagemaker.pipeline import PipelineModel\\n\\n# Preprocessing\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import WordNetLemmatizer\\nfrom string import punctuation \\n\\nfrom tqdm.notebook import tqdm \\ntqdm.pandas()\\n\\nnltk.download('stopwords')\\nnltk.download('punkt')\\nnltk.download('wordnet')\\n\\nprint(f'SageMaker SDK Version: {sagemaker.__version__}')\";\n",
       "                var nbb_formatted_code = \"!pip install sentence_transformers\\n!pip install nvidia-ml-py3\\n\\nimport os\\nimport tarfile\\nimport json\\nimport time\\nimport pandas as pd\\nimport boto3\\nimport joblib\\nimport sagemaker\\nfrom time import gmtime, strftime\\nfrom sagemaker import get_execution_role\\nfrom sagemaker.amazon.amazon_estimator import image_uris\\nfrom sagemaker.serializers import JSONSerializer\\nfrom sagemaker.deserializers import JSONDeserializer\\nfrom sentence_transformers import SentenceTransformer\\nfrom sagemaker.sklearn import SKLearnModel\\nfrom sagemaker.pytorch import PyTorch, PyTorchModel\\nfrom sagemaker.predictor import Predictor\\nfrom sagemaker.inputs import TrainingInput\\nfrom sklearn.neighbors import NearestNeighbors\\nfrom sagemaker.pipeline import PipelineModel\\n\\n# Preprocessing\\nimport nltk\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import WordNetLemmatizer\\nfrom string import punctuation\\n\\nfrom tqdm.notebook import tqdm\\n\\ntqdm.pandas()\\n\\nnltk.download(\\\"stopwords\\\")\\nnltk.download(\\\"punkt\\\")\\nnltk.download(\\\"wordnet\\\")\\n\\nprint(f\\\"SageMaker SDK Version: {sagemaker.__version__}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install nvidia-ml-py3\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import joblib\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "from sagemaker.pytorch import PyTorch, PyTorchModel\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "# Preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from string import punctuation\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe35296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nb_black\n",
      "  Downloading nb_black-1.0.7.tar.gz (4.8 kB)\n",
      "Requirement already satisfied: ipython in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nb_black) (7.16.1)\n",
      "Collecting black>='19.3'\n",
      "  Downloading black-21.12b0-py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 21.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typed-ast>=1.4.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from black>='19.3'->nb_black) (1.4.3)\n",
      "Requirement already satisfied: click>=7.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from black>='19.3'->nb_black) (8.0.1)\n",
      "Collecting pathspec<1,>=0.9.0\n",
      "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting platformdirs>=2\n",
      "  Downloading platformdirs-2.4.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: dataclasses>=0.6 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from black>='19.3'->nb_black) (0.8)\n",
      "Collecting tomli<2.0.0,>=0.2.6\n",
      "  Downloading tomli-1.2.2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from black>='19.3'->nb_black) (3.10.0.2)\n",
      "Collecting mypy-extensions>=0.4.3\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from click>=7.1.2->black>='19.3'->nb_black) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->click>=7.1.2->black>='19.3'->nb_black) (3.6.0)\n",
      "Requirement already satisfied: backcall in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython->nb_black) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython->nb_black) (58.5.3)\n",
      "Requirement already satisfied: pexpect in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython->nb_black) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython->nb_black) (3.0.19)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython->nb_black) (0.17.2)\n",
      "Requirement already satisfied: pygments in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython->nb_black) (2.9.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython->nb_black) (4.3.3)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython->nb_black) (5.0.9)\n",
      "Requirement already satisfied: pickleshare in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ipython->nb_black) (0.7.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from jedi>=0.10->ipython->nb_black) (0.7.1)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->nb_black) (0.2.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from traitlets>=4.2->ipython->nb_black) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from traitlets>=4.2->ipython->nb_black) (0.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pexpect->ipython->nb_black) (0.7.0)\n",
      "Building wheels for collected packages: nb-black\n",
      "  Building wheel for nb-black (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nb-black: filename=nb_black-1.0.7-py3-none-any.whl size=5320 sha256=5fc093aa7775b446bbc8b90edab8c4224b89506eac641ad27a3b1df73168b3fe\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/b8/d1/fe/2f4f49a959887ffe9ebdf841c1a221a5b4eb047a1ca09b50a9\n",
      "Successfully built nb-black\n",
      "Installing collected packages: tomli, platformdirs, pathspec, mypy-extensions, black, nb-black\n",
      "Successfully installed black-21.12b0 mypy-extensions-0.4.3 nb-black-1.0.7 pathspec-0.9.0 platformdirs-2.4.0 tomli-1.2.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"!pip install nb_black\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"!pip install nb_black\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install nb_black\n",
    "%load_ext nb_black\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "664312c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "# bucket = \"<S3_BUCKET>\"\n",
    "# prefix = \"<S3_KEY_PREFIX>\"\n",
    "# filename = \"<DATASET_FILENAME>\"\n",
    "\n",
    "bucket = \"wineinamillion\"\n",
    "prefix = \"data/\"\n",
    "filename = \"winemag-data-130k-v2.csv\"\n",
    "\n",
    "assert bucket != \"<S3_BUCKET>\"\n",
    "assert prefix != \"<S3_KEY_PREFIX>\"\n",
    "assert filename != \"<DATASET_FILENAME>\"\n",
    "\n",
    "raw_data_location = f\"s3://{bucket}/{prefix}raw/{filename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f10de47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.1.20)\n",
      "Requirement already satisfied: kaggle in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from opendatasets) (1.5.12)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from opendatasets) (4.61.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from opendatasets) (8.0.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from click->opendatasets) (4.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->click->opendatasets) (3.10.0.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->click->opendatasets) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle->opendatasets) (2.8.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle->opendatasets) (2.26.0)\n",
      "Requirement already satisfied: python-slugify in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle->opendatasets) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle->opendatasets) (1.26.7)\n",
      "Requirement already satisfied: six>=1.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle->opendatasets) (1.16.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from kaggle->opendatasets) (2021.10.8)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->kaggle->opendatasets) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->kaggle->opendatasets) (3.3)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Skipping, found downloaded files in \"./wine-reviews\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2021/04/how-to-download-kaggle-datasets-using-jupyter-notebook/\n",
    "!pip install opendatasets\n",
    "import opendatasets as od\n",
    "od.download(\"https://www.kaggle.com/zynicide/wine-reviews\")\n",
    "inputs = boto3.resource(\"s3\").Bucket(bucket).upload_file(f\"wine-reviews/{filename}\", f\"{prefix}raw/{filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc3e6bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>129971.000000</td>\n",
       "      <td>129971.000000</td>\n",
       "      <td>120975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>64985.000000</td>\n",
       "      <td>88.447138</td>\n",
       "      <td>35.363389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37519.540256</td>\n",
       "      <td>3.039730</td>\n",
       "      <td>41.022218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32492.500000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>64985.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>97477.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>129970.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>3300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0         points          price\n",
       "count  129971.000000  129971.000000  120975.000000\n",
       "mean    64985.000000      88.447138      35.363389\n",
       "std     37519.540256       3.039730      41.022218\n",
       "min         0.000000      80.000000       4.000000\n",
       "25%     32492.500000      86.000000      17.000000\n",
       "50%     64985.000000      88.000000      25.000000\n",
       "75%     97477.500000      91.000000      42.000000\n",
       "max    129970.000000     100.000000    3300.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(raw_data_location)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4412c38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td>NaN</td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   country                                        description  \\\n",
       "0           0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1           1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2           2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3           3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4           4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points  price           province  \\\n",
       "0                        Vulkà Bianco      87    NaN  Sicily & Sardinia   \n",
       "1                            Avidagos      87   15.0              Douro   \n",
       "2                                 NaN      87   14.0             Oregon   \n",
       "3                Reserve Late Harvest      87   13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87   65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                NaN       Kerin O’Keefe   \n",
       "1                  NaN                NaN          Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                NaN  Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                   NaN  St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d58698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aromas include tropical fruit, broom, brimstone and dried herb. The palate isn't overly expressive, offering unripened apple, citrus and dried sage alongside brisk acidity.\n"
     ]
    }
   ],
   "source": [
    "print(df[\"description\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f45c1f4",
   "metadata": {},
   "source": [
    "# Preprocess Dataframe & Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8e5855a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    aroma include tropical fruit broom brimstone d...\n",
      "1    ripe fruity wine smooth still structured firm ...\n",
      "2    tart snappy flavor lime flesh rind dominate gr...\n",
      "3    pineapple rind lemon pith orange blossom start...\n",
      "4    much like regular bottling 2012 come across ra...\n",
      "Name: clean_desc, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clean_data(desc):\n",
    "    words = stopwords.words('english')\n",
    "    lower = \" \".join([w for w in desc.lower().split() if not w in words])\n",
    "    punct = ''.join(ch for ch in lower if ch not in punctuation)\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    word_tokens = nltk.word_tokenize(punct)\n",
    "    lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "\n",
    "    word_joined = \" \".join(lemmatized_word)\n",
    "    \n",
    "    return word_joined\n",
    "    \n",
    "\n",
    "df['clean_desc'] = df[\"description\"].apply(clean_data)\n",
    "\n",
    "print(df['clean_desc'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ef5633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the preprocessed dataset to S3\n",
    "df.to_csv(\"cleaned_dataset.csv\")\n",
    "clean_data_location = f\"{prefix}clean/cleaned_dataset.csv\"\n",
    "inputs = boto3.resource(\"s3\").Bucket(bucket).upload_file('cleaned_dataset.csv', clean_data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5217cb44",
   "metadata": {},
   "source": [
    "\n",
    "# Sentence-BERT Embeddings\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5933c470",
   "metadata": {},
   "source": [
    "@inproceedings{\n",
    "    reimers-2019-sentence-bert,\n",
    "    title = \"Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\",\n",
    "    author = \"Reimers, Nils and Gurevych, Iryna\",\n",
    "    booktitle = \"Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing\",\n",
    "    month = \"11\",\n",
    "    year = \"2019\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"http://arxiv.org/abs/1908.10084\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37f106df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a69255952fb4f298b89824dc8a17966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c01401b6b1430f8f09fe8a23128d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672e80845cf3429fb087b917f0e96f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48d60c669cc647529a1f1d63e0b67056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b277cfb7469e4b319059ce65f3ff9d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "825c30445e7d492ebe33bea2514ea6c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ceb0e20efb47bea5c9a0f35c29b4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432c1de2eb9f42bfab773cd3ff944159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd625932bf0e4fd48a0122f768e65cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc2930f78af4a0faa4138d28b4c065d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abde634fa0e147dcaa14b59f6ca78081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14f3d982fea47df9b264e856ae0753c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c47e76218aa4e918a9528e5e69df2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612da2c06d624c38a689603c7c38727e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "# Save the model to disk which we will host at sagemaker\n",
    "\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "saved_model_dir = 'transformer'\n",
    "if not os.path.isdir(saved_model_dir):\n",
    "    os.makedirs(saved_model_dir)\n",
    "\n",
    "model = SentenceTransformer(model_name)\n",
    "model.save(saved_model_dir)\n",
    "\n",
    "embeddings = model.encode(df[\"clean_desc\"][0])\n",
    "print(len(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e7ff7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the model .gz format and upload to s3\n",
    "\n",
    "export_dir = 'transformer'\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add(export_dir, recursive=True)\n",
    "\n",
    "\n",
    "#Upload the model to S3\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).upload_file('model.tar.gz', 'model/transformer/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "631413cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a0f4c4df0048e79f515dc6dd40f226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generates embeddings from the model\n",
    "embeddings = []\n",
    "for i in tqdm(range(len(df[\"clean_desc\"])-100,len(df[\"clean_desc\"]))):\n",
    "    vector = model.encode([df[\"clean_desc\"][i]])\n",
    "    embeddings.append(vector)\n",
    "    \n",
    "embeddings_flattened = list(map(lambda x:x[0], embeddings))\n",
    "embeddings_df = pd.DataFrame(embeddings_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd5a49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write embeddings to csv\n",
    "embeddings_df.to_csv('embeddings.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4a53971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Upload the embeddings to S3\\nembeddings_location = (\\n    boto3.Session()\\n    .resource(\\\"s3\\\")\\n    .Bucket(bucket)\\n    .upload_file(\\n        \\\"embeddings.csv.gz\\\", \\\"model/embeddings/embeddings.csv.gzblah\\\"\\n    )\\n)\\n\\nprint(embeddings_location)\";\n",
       "                var nbb_formatted_code = \"# Upload the embeddings to S3\\nembeddings_location = (\\n    boto3.Session()\\n    .resource(\\\"s3\\\")\\n    .Bucket(bucket)\\n    .upload_file(\\\"embeddings.csv.gz\\\", \\\"model/embeddings/embeddings.csv.gzblah\\\")\\n)\\n\\nprint(embeddings_location)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Upload the embeddings to S3\n",
    "embeddings_location = (\n",
    "    boto3.Session()\n",
    "    .resource(\"s3\")\n",
    "    .Bucket(bucket)\n",
    "    .upload_file(\"embeddings.csv.gz\", \"model/embeddings/embeddings.csv.gz\")\n",
    ")\n",
    "\n",
    "print(embeddings_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1576f09d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings.csv</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007083</td>\n",
       "      <td>-0.015033</td>\n",
       "      <td>0.067645</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.013292</td>\n",
       "      <td>0.045818</td>\n",
       "      <td>0.020863</td>\n",
       "      <td>-0.091562</td>\n",
       "      <td>0.027603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043422</td>\n",
       "      <td>0.018685</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.059448</td>\n",
       "      <td>0.07432</td>\n",
       "      <td>-0.023519</td>\n",
       "      <td>0.072006</td>\n",
       "      <td>-0.009756</td>\n",
       "      <td>-0.012147</td>\n",
       "      <td>-0.010488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   embeddings.csv         0         1         2         3         4         5  \\\n",
       "0             0.0  0.007083 -0.015033  0.067645  0.063208  0.013292  0.045818   \n",
       "\n",
       "          6         7         8  ...       374       375       376       377  \\\n",
       "0  0.020863 -0.091562  0.027603  ... -0.043422  0.018685 -0.000122 -0.059448   \n",
       "\n",
       "       378       379       380       381       382       383  \n",
       "0  0.07432 -0.023519  0.072006 -0.009756 -0.012147 -0.010488  \n",
       "\n",
       "[1 rows x 385 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to have the embeddings as a tarball in s3\n",
    "embeddings_location = f\"s3://{bucket}/embeddings.csv.gz\"\n",
    "df = pd.read_csv(embeddings_location)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c13d5",
   "metadata": {},
   "source": [
    "# Create Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b6942cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = PyTorchModel(\n",
    "    model_data=f\"s3://{bucket}/model/transformer/model.tar.gz\",\n",
    "    role = role, \n",
    "    entry_point ='encode_inference.py',\n",
    "    source_dir = './src', \n",
    "    framework_version = '1.9.0',\n",
    "    py_version = 'py38',\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c70347",
   "metadata": {},
   "source": [
    "### Test Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bc77330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "embeddings_endpoint_name = \"embeddings-model-ep-\" + timestamp_prefix\n",
    "\n",
    "embedding_predictor = embeddings_model.deploy(\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=embeddings_endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "70ff1bee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint embeddings-model-ep-2021-12-10-17-27-26 of account 985074551727 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-15948337d657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m test_embedding = embedding_predictor.predict(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"sweet wine with a hint of tartness\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint embeddings-model-ep-2021-12-10-17-27-26 of account 985074551727 not found."
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 235;\n",
       "                var nbb_unformatted_code = \"# test_payload = {'data': 'sweet wine with a hint of tartness'}\\n# test_features = embeddings_predictor.predict(test_payload)\\n# test_embedding = json.loads(test_features)\\n\\n# len(test_embedding)\\n\\ntest_embedding = embedding_predictor.predict(\\n    {\\\"data\\\": \\\"sweet wine with a hint of tartness\\\"}\\n)\\nprint(len(test_embedding[\\\"embeddings\\\"]))\";\n",
       "                var nbb_formatted_code = \"# test_payload = {'data': 'sweet wine with a hint of tartness'}\\n# test_features = embeddings_predictor.predict(test_payload)\\n# test_embedding = json.loads(test_features)\\n\\n# len(test_embedding)\\n\\ntest_embedding = embedding_predictor.predict(\\n    {\\\"data\\\": \\\"sweet wine with a hint of tartness\\\"}\\n)\\nprint(len(test_embedding[\\\"embeddings\\\"]))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_payload = {'data': 'sweet wine with a hint of tartness'}\n",
    "# test_features = embeddings_predictor.predict(test_payload)\n",
    "# test_embedding = json.loads(test_features)\n",
    "\n",
    "# len(test_embedding)\n",
    "\n",
    "test_embedding = embedding_predictor.predict(\n",
    "    {\"data\": \"sweet wine with a hint of tartness\"}\n",
    ")\n",
    "print(len(test_embedding[\"embeddings\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa195a0b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Nearest Neighbors Model \"Training\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7e57812f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 156;\n",
       "                var nbb_unformatted_code = \"# This is only a caching sort of step.  Instead of regenerating on subsequent runs, this can be run to pull the intermediary data from s3\\nembeddings_df = pd.read_csv(f\\\"s3://{bucket}/model/embeddings/embeddings.csv.gz\\\")\";\n",
       "                var nbb_formatted_code = \"# This is only a caching sort of step.  Instead of regenerating on subsequent runs, this can be run to pull the intermediary data from s3\\nembeddings_df = pd.read_csv(f\\\"s3://{bucket}/model/embeddings/embeddings.csv.gz\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is only a caching sort of step.  Instead of regenerating on subsequent runs, this can be run to pull the intermediary data from s3\n",
    "embeddings_df = pd.read_csv(f\"s3://{bucket}/model/embeddings/embeddings.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b51adcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>129966</th>\n",
       "      <td>-0.014324</td>\n",
       "      <td>-0.083236</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>0.055890</td>\n",
       "      <td>-0.014183</td>\n",
       "      <td>0.088444</td>\n",
       "      <td>0.044363</td>\n",
       "      <td>-0.069194</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>-0.027660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053791</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>0.052278</td>\n",
       "      <td>-0.019380</td>\n",
       "      <td>0.022829</td>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.019275</td>\n",
       "      <td>-0.022067</td>\n",
       "      <td>0.055997</td>\n",
       "      <td>-0.046584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129967</th>\n",
       "      <td>0.067471</td>\n",
       "      <td>-0.044725</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.059453</td>\n",
       "      <td>0.028468</td>\n",
       "      <td>0.070333</td>\n",
       "      <td>-0.028098</td>\n",
       "      <td>0.062695</td>\n",
       "      <td>-0.033304</td>\n",
       "      <td>-0.010947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026852</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>0.039433</td>\n",
       "      <td>-0.010654</td>\n",
       "      <td>-0.005636</td>\n",
       "      <td>-0.012233</td>\n",
       "      <td>0.169666</td>\n",
       "      <td>-0.054893</td>\n",
       "      <td>0.075262</td>\n",
       "      <td>0.021987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129968</th>\n",
       "      <td>0.024301</td>\n",
       "      <td>-0.016125</td>\n",
       "      <td>0.075865</td>\n",
       "      <td>0.050819</td>\n",
       "      <td>0.006110</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>-0.041206</td>\n",
       "      <td>-0.076532</td>\n",
       "      <td>-0.063111</td>\n",
       "      <td>-0.045451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019010</td>\n",
       "      <td>0.086116</td>\n",
       "      <td>0.029834</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.012753</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>-0.019980</td>\n",
       "      <td>0.018332</td>\n",
       "      <td>-0.111340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129969</th>\n",
       "      <td>0.015386</td>\n",
       "      <td>-0.082658</td>\n",
       "      <td>-0.027251</td>\n",
       "      <td>0.032489</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>-0.017528</td>\n",
       "      <td>-0.017251</td>\n",
       "      <td>-0.020987</td>\n",
       "      <td>-0.010176</td>\n",
       "      <td>-0.079221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004047</td>\n",
       "      <td>0.056436</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>-0.080968</td>\n",
       "      <td>0.071581</td>\n",
       "      <td>-0.031942</td>\n",
       "      <td>0.101251</td>\n",
       "      <td>-0.043256</td>\n",
       "      <td>0.036289</td>\n",
       "      <td>-0.010412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129970</th>\n",
       "      <td>0.053372</td>\n",
       "      <td>-0.087436</td>\n",
       "      <td>0.053435</td>\n",
       "      <td>0.033393</td>\n",
       "      <td>0.010193</td>\n",
       "      <td>0.037103</td>\n",
       "      <td>0.038221</td>\n",
       "      <td>0.028853</td>\n",
       "      <td>-0.075111</td>\n",
       "      <td>-0.023183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007885</td>\n",
       "      <td>-0.023440</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>-0.031840</td>\n",
       "      <td>-0.060474</td>\n",
       "      <td>0.095480</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.040922</td>\n",
       "      <td>-0.045540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "129966 -0.014324 -0.083236  0.021317  0.055890 -0.014183  0.088444  0.044363   \n",
       "129967  0.067471 -0.044725 -0.000028  0.059453  0.028468  0.070333 -0.028098   \n",
       "129968  0.024301 -0.016125  0.075865  0.050819  0.006110  0.016331 -0.041206   \n",
       "129969  0.015386 -0.082658 -0.027251  0.032489  0.007341 -0.017528 -0.017251   \n",
       "129970  0.053372 -0.087436  0.053435  0.033393  0.010193  0.037103  0.038221   \n",
       "\n",
       "               7         8         9  ...       374       375       376  \\\n",
       "129966 -0.069194  0.002302 -0.027660  ...  0.053791  0.031073  0.052278   \n",
       "129967  0.062695 -0.033304 -0.010947  ... -0.026852  0.003229  0.039433   \n",
       "129968 -0.076532 -0.063111 -0.045451  ...  0.019010  0.086116  0.029834   \n",
       "129969 -0.020987 -0.010176 -0.079221  ... -0.004047  0.056436  0.014520   \n",
       "129970  0.028853 -0.075111 -0.023183  ... -0.007885 -0.023440  0.000868   \n",
       "\n",
       "             377       378       379       380       381       382       383  \n",
       "129966 -0.019380  0.022829  0.036835  0.019275 -0.022067  0.055997 -0.046584  \n",
       "129967 -0.010654 -0.005636 -0.012233  0.169666 -0.054893  0.075262  0.021987  \n",
       "129968  0.000319  0.012753  0.001713  0.011256 -0.019980  0.018332 -0.111340  \n",
       "129969 -0.080968  0.071581 -0.031942  0.101251 -0.043256  0.036289 -0.010412  \n",
       "129970  0.031423 -0.031840 -0.060474  0.095480  0.002652  0.040922 -0.045540  \n",
       "\n",
       "[5 rows x 384 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 158;\n",
       "                var nbb_unformatted_code = \"embeddings_df = embeddings_df[:-1]\\n\\nembeddings_df.tail(5)\\n# del embeddings_df[\\\"embeddings.csv\\\"]\\nembeddings_df.tail(5)\";\n",
       "                var nbb_formatted_code = \"embeddings_df = embeddings_df[:-1]\\n\\nembeddings_df.tail(5)\\n# del embeddings_df[\\\"embeddings.csv\\\"]\\nembeddings_df.tail(5)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings_df = embeddings_df[:-1]\n",
    "\n",
    "embeddings_df.tail(5)\n",
    "del embeddings_df[\"embeddings.csv\"]\n",
    "embeddings_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4b9ee460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 159;\n",
       "                var nbb_unformatted_code = \"neigh = NearestNeighbors(n_neighbors=5)\\nneigh.fit(embeddings_df)\\n\\njoblib.dump(neigh, \\\"model.joblib\\\")\\nwith tarfile.open(\\\"model.joblib.tar.gz\\\", mode=\\\"w:gz\\\") as archive:\\n    archive.add(\\\"model.joblib\\\")\\n\\ninputs = (\\n    boto3.resource(\\\"s3\\\")\\n    .Bucket(bucket)\\n    .upload_file(\\\"model.joblib.tar.gz\\\", \\\"model/nn/model.joblib.tar.gz\\\")\\n)\";\n",
       "                var nbb_formatted_code = \"neigh = NearestNeighbors(n_neighbors=5)\\nneigh.fit(embeddings_df)\\n\\njoblib.dump(neigh, \\\"model.joblib\\\")\\nwith tarfile.open(\\\"model.joblib.tar.gz\\\", mode=\\\"w:gz\\\") as archive:\\n    archive.add(\\\"model.joblib\\\")\\n\\ninputs = (\\n    boto3.resource(\\\"s3\\\")\\n    .Bucket(bucket)\\n    .upload_file(\\\"model.joblib.tar.gz\\\", \\\"model/nn/model.joblib.tar.gz\\\")\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "neigh.fit(embeddings_df)\n",
    "\n",
    "joblib.dump(neigh, \"model.joblib\")\n",
    "with tarfile.open(\"model.joblib.tar.gz\", mode=\"w:gz\") as archive:\n",
    "    archive.add(\"model.joblib\")\n",
    "\n",
    "inputs = (\n",
    "    boto3.resource(\"s3\")\n",
    "    .Bucket(bucket)\n",
    "    .upload_file(\"model.joblib.tar.gz\", \"model/nn/model.joblib.tar.gz\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c961b60",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8a212115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 225;\n",
       "                var nbb_unformatted_code = \"timestamp_prefix = strftime(\\\"%Y-%m-%d-%H-%M-%S\\\", gmtime())\\n\\nnn_endpoint_name = \\\"nn-model-ep-\\\" + timestamp_prefix\\n\\nnn_model = SKLearnModel(\\n    model_data=f\\\"s3://{bucket}/model/nn/model.joblib.tar.gz\\\",\\n    role=role,\\n    entry_point=\\\"src/nn_inference.py\\\",\\n    framework_version=\\\"0.23-1\\\",\\n    sagemaker_session=sagemaker.Session(),\\n)\";\n",
       "                var nbb_formatted_code = \"timestamp_prefix = strftime(\\\"%Y-%m-%d-%H-%M-%S\\\", gmtime())\\n\\nnn_endpoint_name = \\\"nn-model-ep-\\\" + timestamp_prefix\\n\\nnn_model = SKLearnModel(\\n    model_data=f\\\"s3://{bucket}/model/nn/model.joblib.tar.gz\\\",\\n    role=role,\\n    entry_point=\\\"src/nn_inference.py\\\",\\n    framework_version=\\\"0.23-1\\\",\\n    sagemaker_session=sagemaker.Session(),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "nn_endpoint_name = \"nn-model-ep-\" + timestamp_prefix\n",
    "\n",
    "nn_model = SKLearnModel(\n",
    "    model_data=f\"s3://{bucket}/model/nn/model.joblib.tar.gz\",\n",
    "    role=role,\n",
    "    entry_point=\"src/nn_inference.py\",\n",
    "    framework_version=\"0.23-1\",\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "78c9c06a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 226;\n",
       "                var nbb_unformatted_code = \"nn_predictor = nn_model.deploy(\\n    instance_type=\\\"ml.m4.xlarge\\\",\\n    initial_instance_count=1,\\n    endpoint_name=nn_endpoint_name,\\n)\";\n",
       "                var nbb_formatted_code = \"nn_predictor = nn_model.deploy(\\n    instance_type=\\\"ml.m4.xlarge\\\",\\n    initial_instance_count=1,\\n    endpoint_name=nn_endpoint_name,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_predictor = nn_model.deploy(\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=nn_endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5787aa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'recommendations': [[5792, 0.6971731262020007], [99509, 0.7127081025413139], [87946, 0.7221756314556704], [126268, 0.7293226724388949], [51012, 0.7328417131487005]]}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 227;\n",
       "                var nbb_unformatted_code = \"predictor = Predictor(\\n    endpoint_name=nn_endpoint_name,\\n    sagemaker_session=sagemaker.Session(),\\n    serializer=JSONSerializer(),\\n    deserializer=JSONDeserializer(),\\n)\\n\\nprediction = predictor.predict(\\n    {\\\"embeddings\\\": test_embedding[\\\"embeddings\\\"], \\\"kneighbors\\\": 5}\\n)\\nprint(prediction)\\n# zipped = list(\\n#     zip(\\n#         prediction[\\\"recommendations\\\"][\\\"neighbors\\\"][0],\\n#         prediction[\\\"recommendations\\\"][\\\"distance\\\"][0],\\n#     )\\n# )\";\n",
       "                var nbb_formatted_code = \"predictor = Predictor(\\n    endpoint_name=nn_endpoint_name,\\n    sagemaker_session=sagemaker.Session(),\\n    serializer=JSONSerializer(),\\n    deserializer=JSONDeserializer(),\\n)\\n\\nprediction = predictor.predict(\\n    {\\\"embeddings\\\": test_embedding[\\\"embeddings\\\"], \\\"kneighbors\\\": 5}\\n)\\nprint(prediction)\\n# zipped = list(\\n#     zip(\\n#         prediction[\\\"recommendations\\\"][\\\"neighbors\\\"][0],\\n#         prediction[\\\"recommendations\\\"][\\\"distance\\\"][0],\\n#     )\\n# )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictor = Predictor(\n",
    "    endpoint_name=nn_endpoint_name,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")\n",
    "\n",
    "prediction = predictor.predict(\n",
    "    {\"embeddings\": test_embedding[\"embeddings\"], \"kneighbors\": 5}\n",
    ")\n",
    "print(prediction)\n",
    "# zipped = list(\n",
    "#     zip(\n",
    "#         prediction[\"recommendations\"][\"neighbors\"][0],\n",
    "#         prediction[\"recommendations\"][\"distance\"][0],\n",
    "#     )\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b5894",
   "metadata": {},
   "source": [
    "\n",
    "# Inference Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d6aece32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 229;\n",
       "                var nbb_unformatted_code = \"timestamp_prefix = strftime(\\\"%Y-%m-%d-%H-%M-%S\\\", gmtime())\\nendpoint_name = \\\"inference-pipeline-ep-\\\" + timestamp_prefix\\npipeline_model = PipelineModel(\\n    role=role, \\n    models=[\\n        embeddings_model, \\n        nn_model\\n    ],\\n    sagemaker_session=sagemaker.Session(),\\n)\";\n",
       "                var nbb_formatted_code = \"timestamp_prefix = strftime(\\\"%Y-%m-%d-%H-%M-%S\\\", gmtime())\\nendpoint_name = \\\"inference-pipeline-ep-\\\" + timestamp_prefix\\npipeline_model = PipelineModel(\\n    role=role,\\n    models=[embeddings_model, nn_model],\\n    sagemaker_session=sagemaker.Session(),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "endpoint_name = \"inference-pipeline-ep-\" + timestamp_prefix\n",
    "pipeline_model = PipelineModel(\n",
    "    role=role, \n",
    "    models=[\n",
    "        embeddings_model, \n",
    "        nn_model\n",
    "    ],\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7301d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------"
     ]
    }
   ],
   "source": [
    "inference_pipeline = pipeline_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "4262ecc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 233;\n",
       "                var nbb_unformatted_code = \"pipeline_predictor = Predictor(\\n    endpoint_name='inference-pipeline-ep-2021-12-10-23-25-18',\\n    sagemaker_session=sagemaker.Session(),\\n    serializer=JSONSerializer(),\\n    deserializer=JSONDeserializer(),\\n)\";\n",
       "                var nbb_formatted_code = \"pipeline_predictor = Predictor(\\n    endpoint_name=\\\"inference-pipeline-ep-2021-12-10-23-25-18\\\",\\n    sagemaker_session=sagemaker.Session(),\\n    serializer=JSONSerializer(),\\n    deserializer=JSONDeserializer(),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e58e978",
   "metadata": {},
   "source": [
    "# Test Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "d9ae0c7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint inference-pipeline-ep-2021-12-10-23-25-18 of account 985074551727 not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-88cf70b88a8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_payload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"sweet wine with a hint of tartness\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_payload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# test_recommendations = json.loads(test_response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_recommentations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, initial_args, target_model, target_variant, inference_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_runtime_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mrequest_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: An error occurred (ValidationError) when calling the InvokeEndpoint operation: Endpoint inference-pipeline-ep-2021-12-10-23-25-18 of account 985074551727 not found."
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 234;\n",
       "                var nbb_unformatted_code = \"test_payload = json.dumps({\\\"data\\\": \\\"sweet wine with a hint of tartness\\\"})\\ntest_response = pipeline_predictor.predict(data=test_payload)\\n# test_recommendations = json.loads(test_response)\\n\\nprint(test_recommentations)\";\n",
       "                var nbb_formatted_code = \"test_payload = json.dumps({\\\"data\\\": \\\"sweet wine with a hint of tartness\\\"})\\ntest_response = pipeline_predictor.predict(data=test_payload)\\n# test_recommendations = json.loads(test_response)\\n\\nprint(test_recommentations)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_payload = json.dumps({\"data\": \"sweet wine with a hint of tartness\"})\n",
    "test_response = pipeline_predictor.predict(data=test_payload)\n",
    "# test_recommendations = json.loads(test_response)\n",
    "\n",
    "print(test_recommentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fdc02b",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3703ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "embeddings_model.delete_model()\n",
    "nn_model.delete_model()\n",
    "pipeline_predictor.delete_model()\n",
    "\n",
    "# Delete endpoint and endpoint configuration\n",
    "embeddings_predictor.delete_predictor()\n",
    "nn_predictor.delete_predictor()\n",
    "pipeline_predictor.delete_predictor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
